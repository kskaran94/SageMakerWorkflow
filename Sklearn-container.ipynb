{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Training and Prediction with Sagemaker Scikit-learn\n",
    "This tutorial shows you how to use Scikit-learn with Sagemaker by utilizing the pre-built container. Scikit-learn is a popular Python machine learning framework. It includes a number of different algorithms for classification, regression, clustering, dimensionality reduction, and data/feature pre-processing.\n",
    "\n",
    "The sagemaker-python-sdk module makes it easy to take existing scikit-learn code, which we will show by training a model on the IRIS dataset and generating a set of predictions. For more information about the Scikit-learn container, see the sagemaker-scikit-learn-containers repository and the sagemaker-python-sdk repository.\n",
    "\n",
    "For more on Scikit-learn, please visit the Scikit-learn website: http://scikit-learn.org/stable/.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import os\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions and environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session(default_bucket='test-karan-02')\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "bucket = 'test-karan-02'\n",
    "prefix = 'sagemaker_demo_scikit'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-02 21:48:48--  https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... --2020-03-02 21:48:48--  https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "connected.\n",
      "HTTP request sent, awaiting response... HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4551 (4.4K) [application/x-httpd-php]\n",
      "Saving to: ‘iris.data.1’\n",
      "\n",
      "iris.data.1         100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-02 21:48:48 (107 MB/s) - ‘iris.data.1’ saved [4551/4551]\n",
      "\n",
      "200 OK\n",
      "Length: 4551 (4.4K) [application/x-httpd-php]\n",
      "Saving to: ‘iris.data.1’\n",
      "\n",
      "iris.data.1         100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-02 21:48:48 (107 MB/s) - ‘iris.data.1’ saved [4551/4551]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv(\"iris.data\", header = None)\n",
    "\n",
    "iris_df.columns = ['sepal_length', 'sepal_width','petal_length','petal_width', 'class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df['class'] = pd.Categorical(iris_df['class'])\n",
    "\n",
    "iris_df['code_class'] = iris_df['class'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del iris_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = iris_df.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://test-karan-02/sagemaker_demo_scikit/train.csv\n",
      "uploaded training data location: s3://test-karan-02/sagemaker_demo_scikit/train.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "key = 'train.csv'\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, key)).upload_file('train.csv')\n",
    "s3_train_data = 's3://{}/{}/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = sagemaker_session.upload_data(\"train.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training artifacts will be uploaded to: s3://test-karan-02/sagemaker_demo_scikit/output/\n",
      "training artifacts will be uploaded to: s3://test-karan-02/sagemaker_demo_scikit/output/\n"
     ]
    }
   ],
   "source": [
    "output_location = 's3://{}/{}/output/'.format(bucket, prefix)\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://test-karan-02/data/train.csv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'s3://test-karan-02/data/train.csv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = 'scikit_iris_v2.py'\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={'max_leaf_nodes': 30})\n",
    "\n",
    "\n",
    "sklearn.fit({'train': s3_train_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hosting for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------!!"
     ]
    }
   ],
   "source": [
    "predictor = sklearn.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.content_type = 'text/csv'\n",
    "predictor.serializer = csv_serializer\n",
    "predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(iris_df.iloc[30,:4])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
